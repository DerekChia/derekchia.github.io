---
layout: post
title:  "An implementation guide to Word2Vec using NumPy and Google Sheets!"
date:   2018-12-06 00:00:00 +0800
# categories: main
---
Word2Vec is touted as one of the biggest, most recent breakthrough in the field of Natural Language Processing (NLP). The concept is simple, elegant and (relatively) easy to grasp. A quick Google search returns multiple results on how to use them with standard libraries such as [Gensim](https://radimrehurek.com/gensim/models/word2vec.html) and [TensorFlow](https://www.tensorflow.org/tutorials/representation/word2vec). Also, for the curious minds, check out the original implementation using C by [Tomas Mikolov](https://github.com/tmikolov/word2vec). The original paper can be found [here](https://arxiv.org/pdf/1301.3781.pdf) too.

The main focus on this article is to present Word2Vec in detail. For that, I implemented Word2Vec on Python using NumPy (with much help from other tutorials) and also prepared a Google Sheet to showcase the calculations. Here are the links to the [code](https://github.com/DerekChia/word2vec_numpy) and [Google Sheet](https://docs.google.com/spreadsheets/u/3/d/1mgf82Ue7MmQixMm2ZqnT1oWUucj6pEcd2wDs_JgHmco/edit).

![Image]({{ site.baseurl }}/assets/images/word2vec-gsheets.png){: width="100%" }

